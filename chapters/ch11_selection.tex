\chapter{Event Selection}

\label{ch:selection}

The \acp{LLP} targeted by this search differ in their interactions with the detector from \ac{SM} particles primarily because of their large mass. 
When produced at the energies available at the \ac{LHC}, that large mass results in a low $\beta$ and such slow-moving particles heavily ionize in detector material. 
Each layer of the pixel detector provides a measurement of that ionization, through \ac{ToT}, as discussed in Section~\ref{sec:pixel}. 
The ionization in the pixel detector, quantified in terms of \dedx, provides the major focus for this search technique, both for its discriminating power and also because of the large range of lifetimes where it can be used. The \dedx variable needs to be augmented with a few additional selection requirements to form a complete search. 

Ionization is not currently available in any form during triggering, so this search instead relies on \met to trigger signal events.
Although triggering on \met is not particularly efficient, \met is often large for many production mechanisms of \acp{LLP}, as discussed in Section~\ref{sec:characteristics}.

Ionization is most effective in rejecting backgrounds for well-measured, high-momentum tracks, so some basic requirements on quality and kinematics are placed on the particles considered in this search. 
In particular a newly introduced tracking variable is very effective in removing highly-ionizing backgrounds caused by overlapping tracks. 
A few additional requirements are placed on the tracks considered for \ac{LLP} candidates that increase background rejection by targeting specific types of \ac{SM} particles. 
These techniques provide a significant analysis improvement over previous iterations of ionization-based searches on ATLAS by providing additional background rejection with minimal loss in signal efficiency. 

The ionization measurement with the Pixel detector can be calibrated to provide an estimator of $\beta\gamma$. That estimate, together with the momentum measurement provided by tracking, can be used to reconstruct a mass for each track which traverses the pixel detector. 
That mass variable will be peaked at the \ac{LLP} mass for any signal, and provides an additional tool to search for an excess.
In addition to an explicit requirement on ionization, this search constructs a mass-window for each targeted mass range in order to evaluate any excess of events and to set limits. 
%Construction, calibration, and requirements for the mass variable are discussed in Section~\ref{sec:mass_requirement}.

The strategy discussed here is optimized for lifetimes of $O(1)$ - $O(10)$ ns. 
Pixel ionization is especially useful in this regime as particles only need to propagate through the first seven layers of the inner detector, about 37 cm from the beam axis. 
The search is still competitive with other searches for \acp{LLP} at longer lifetimes, because the primary discriminating variables are still applicable even for particles that do not decay within the detector. 
Although the basic strategy remains the same for all lifetimes, two signal regions are defined to optimize separately for intermediate and long lifetime particles.


% --------------------------------------------------------------------------------

\section{Trigger}

Triggering remains one of the primary difficulties in defining an event selection with high signal efficiency in a search for \acp{LLP}. 
There are no triggers available in the current ATLAS system that can fire directly from a high momentum track with large ionization (Section~\ref{sec:trigger}). 
Although in some configurations a charged \ac{LLP} can fire muon triggers, this requirement introduces significant model dependence on both the allowed lifetimes and the interactions in the calorimeter.

For a search targetting particles which may decay prior to reaching the muon system, the most efficient available trigger is based on missing energy.
As discussed in Section~\ref{sec:characteristics}, signal events can produce \met by two primary mechanisms.
The decays of \rhadrons to neutralinos can produce missing energy when the neutralinos go undetected in the calorimeters.
\acp{LLP} which do not decay before the calorimeters also can produce missing energy because they do not deposit much energy. 
Either case to some extent relies on kinematic degrees of freedom to produce missing energy, as the pair-produced \acp{LLP} tend to balance each other in the transverse plain.
That balance results in a relatively low efficiency for long-lifetime particles, roughly 40\%, and efficiencies between 65\% and 95\% for shorter lifetimes depending on both the mass and the lifetime, as seen in Figure~\ref{fig:trigger_efficiency}. 

\begin{figure}[h]
\centering
\includegraphics[draft, width=.68\textwidth]{figures/trigger_efficiency.pdf}
\caption{The trigger efficiency of the \met trigger as a function of mass and lifetime.}
\label{fig:trigger_efficiency}
\end{figure}

% ----------------------------------------

\section{Kinematics and Isolation}
\label{sec:track_requirements}

After the trigger requirement, each event is required to have a primary vertex reconstructed from at least two well-measured tracks in the inner detector, each with $\pt > 400$ MeV. 
If more than one such vertex exists, the primary vertex is taken to be the one with the largest summed track momentum for all tracks associated to that vertex. 
The offline reconstructed \met is required to be above 130 GeV to additionally reject \ac{SM} backgrounds.
The transverse missing energy is calculated using fully reconstructed and calibrated offline objects, as described in Section~\ref{sec:missing_energy}. 
In particular the \met definition in this selection uses jets reconstructed with the anti-$k_t$ algorithm with radius $R = 0.4$ from clusters of energy in the calorimeter (Section~\ref{sec:jets}) and with $p_T > 20$ \GeV, as well as reconstructed muons, electrons, and tracks not identified as another object type.

The \met distributions are shown for data and a few simulated signals in Figure~\ref{fig:nm1_met}, after the trigger requirement.
The cut placed at 130 GeV is 95\% efficient for metastable and 90\% efficient for stable particles, because of the missing energy generating mechanisms discussed previously.
The distribution of data in this figure and subsequent figures in this section can be interpreted as the distribution of backgrounds, as any signal contamination would be negligible if present at these early stages of the selection (prior to the final requirement on mass). 
The background falls rapidly with missing energy, motivating the direct requirement on \met for the signal region.
Although a tigher requirement than the specified value of 130 \GeV would seem to increase the search potential from these early distributions, other requirements are more optimal when taken as a whole.
The specific values for each requirement in signal region were optimized considering the increase in discovery reach for tightening the requirement on each discriminating variable. \textbf{NOTE: Is it interesting to discuss the signal region optimization process in detail? I could add another section on how the values were determined, although in truth it is at least partially historical precedence.}

\begin{figure}[h]
\centering
\includegraphics[width=\fullfig]{figures/selection_met_nm1_log.pdf}
\caption{The distribution of \met for data and simulated signal events, after the trigger requirement.}
\label{fig:nm1_met}
\end{figure}

Potential signal events are then required to have at least one candidate \ac{LLP} track.
Although the \acp{LLP} are produced in pairs, many models do not consistently yield two charged particles.
For example, in the \rhadron model highlighted here, only 20\% of events have two charged \rhadrons while 47\% of events have just one.
A signal region requiring two charged candidates could be a powerful improvement in background rejection for a larger dataset, but it is not considered in this version of the analysis as it was found to be unnecessary to reject the majority of backgrounds.

For a track to be selected as a candidate, it must have $p_T > 50$ \GeV and pass basic quality requirements. 
The track must be associated to the primary vertex.
It must also have at least seven clusters in the silicon layers in the inner detector to ensure an accurate measurement of momentum.
Those clusters must include one in the innermost layer if the extrapolated track is expected to pass through that layer.
And to ensure a reliable measurement of ionization, the track is required to have at least two clusters in the pixel detector that provide a measurement of \dedx.

At this point in the selection, there is a significant high-ionization background from multiple tracks that significantly overlap in the inner detector. 
Previous version of this analysis have rejected these overlaps by an explicit overlap rejection between pairs of fully reconstructed tracks, typically by requiring no additional tracks within a cone around the candidate. 
This technique, however, fails to remove the background from tracks that overlap so precisely that the tracks cannot be separately resolved.

A new method, added in Run 2, identifies cluster shapes that are likely formed by multiple tracks based on a neural network classification algorithm. 
The number of clusters that are classified this way in the pixel detector for a given track is called \Nsplit.
As the shape of clusters requires significantly less spatial separation to identify overlaps than it does to reconstruct two fully resolved tracks, this variable is more effective at rejecting backgrounds from overlaps.
Figure~\ref{fig:dedx_nsplit} shows the dependence of ionization on \Nsplit; as \Nsplit increases the mean of \dedx grows significantly up to twice the expected value when $\Nsplit = 4$. 

\begin{figure}[h]
\centering
\includegraphics[width=\fullfig]{figures/dedx_nsplit_data.pdf}
\caption{The dependence of \dedx on $N_{\mathrm{split}}$ in data after basic track hit requirements have been applied.}
\label{fig:dedx_nsplit}
\end{figure}

This requirement is very succesful in reducing the long positive tail of the \dedx distributions, as can be seen in Figure~\ref{fig:dedx_isolation}.
Comparing the distribution for ``baseline tracks'', tracks with only the above requirements on clusters applied and before the requirement on \Nsplit, to the distribution with $\Nsplit = 0$, it is clear that the fraction of tracks with large \dedx is reduced be several orders of magnitude.
The isolated tracks are very close to the \dedx distribution of identified muons, which are extremely well isolated on average. 
Figure~\ref{fig:dedx_isolation} also includes the distribution of \dedx in an example signal simulation to demonstrate how effective \dedx is as a discriminating variable with this isolation applied. 
The background falls rapidly for $\dedx > 1.8$ \MeVgcm while the majority of the signal, approximately 90\% depending on the mass, falls above that threshold.
Over 90\% of \ac{LLP} tracks in simulated signal events pass the \Nsplit-based isolation requirement.


\begin{figure}[h]
\centering
\includegraphics[width=\fullfig]{figures/dedx_isolation.pdf}
\caption{The distribution of \dedx with various selections applied in data and simulated signal events.}
\label{fig:dedx_isolation}
\end{figure}

A few additional kinematic requirements are imposed to help reduce \ac{SM} backgrounds. 
The momentum of the candidate track must be at least 150 \GeV, and the uncertainty on that measurement must be less than 50\%. 
The distribution of momentum is shown in Figure~\ref{fig:nm1_p} for tracks in data and simulated signal events after the previously discussed requirements on clusters, transverse momentum, and isolation have been imposed.
The signal particles are much harder on average than their backgrounds because of the high energy interactions required to produce them.
The transverse mass, \mt, defined as 

\begin{equation}
 \mt = \sqrt{2 \pt \met (1-\cos(\Delta\phi (\met,\mathrm{track})) ) }
\end{equation}

\noindent is required to be greater than 130 \GeV to reject contributions from the decay of W bosons.
Figure~\ref{fig:nm1_mt} shows the distribution of \mt for data and simulated events. \textbf{More comments to follow.}


\begin{figure}[h]
\centering
\includegraphics[width=\fullfig]{figures/selection_p_nm1.pdf}
\caption{The distribution of track momentum for data and simulated signal events, after previous selection requirements have been applied.}
\label{fig:nm1_p}
\end{figure}


\begin{figure}[h]
\centering
\includegraphics[draft, width=\fullfig]{figures/selection_mt_nm1.pdf}
\caption{The distribution of $M_T$ for data and simulated signal events, after previous selection requirements have been applied.}
\label{fig:nm1_mt}
\end{figure}

% ----------------------------------------

\section{Standard Model Rejection}
\label{sec:sm_rejection}

Because the search selects events with just a single, highly-ionizing track, backgrounds can be formed by a wide variety of \ac{SM} processes when various charged particles have a few randomly large deposits of energy in the pixel detector.
Those backgrounds can be effectively rejected by targeting the types of particles produced rather than the processes which produce them, as \acp{LLP} will have significant differences compared to any \ac{SM} particle.
These rejections focus on using additional features of the event, other than the kinematics or ionization of the candidate track, as it provides a powerful source of background rejection with very high signal efficiency.
The lifetime of the particle can significantly change its detector characteristics, as discussed in Section~\ref{sec:characteristics}.
To accomodate these differences, the \ac{SM} rejections defined in this section are split to form two signal regions, one for long-lifetimes particles, the ``stable'' region, and one for intermediate lifetime particles, the ``metastable'' region.

Jets can be very effectively rejected by considering the larger-scale isolation of the candidate track.
In this case the isolation focuses on the production of nearby particles as a jet-veto, rather than isolation from overlapping tracks to reduce high-ionization backgrounds.
As explained in Section~\ref{sec:characteristics}, the fragmentation process which produces an \rhadron is very hard and thus is not expected to produce additional particles.
The jet-veto uses the summed momentum of tracks with a cone of $\Delta R < 0.25$, referred to as \ptcone, which is shown in Figure~\ref{fig:nm1_isopt} for data and simulated signal events. 
In the data this value has a peak at zero from isolated tracks such as leptons, and a long tail from jets which contains as much as 80\% of the background above 20 \GeV at this stage of the selection.
In signal events \ptcone is strongly peaked at zero and significantly less than 1\% is above 20 \GeV. 
This makes a requirement of $\ptcone < 20$ \GeV one of the most effective methods to reject background without losing signal efficiency.
For the stable signal region, this cut is further tightened to $\ptcone < 5$ \GeV as it is the most effective variable remaining to extend the search reach for long lifetimes. 

\begin{figure}[h]
\centering
\includegraphics[width=\fullfig]{figures/selection_isopt_nm1.pdf}
\caption{The distribution of summed tracked momentum within a cone of $\Delta R < 0.25$ around the candidate track for data and simulated signal events, after previous selection requirements have been applied.}
\label{fig:nm1_isopt}
\end{figure}

Even for fully isolated particles, there are additional methods to reject each type of particle using information in the muon system and calorimeters.
Muons can be identified very reliably using the tracks in the muon system, as described in Section~\ref{sec:muons}.
For intermediate lifetimes the \acp{LLP} do not survive long enough to reach the muon system, and so muons are vetoed by rejecting tracks that associate to a muon with medium muon identification requirements.
For longer lifetimes, this rejection is not applied because \acp{LLP} which reach the muon system can be identified as muons as often as 30\% of the time in simulated samples.

Calorimeter-based particle rejection relies on the expected small deposits of energy from \acp{LLP}. 
When the lifetime is long enough to reach the calorimeter, a \ac{LLP} deposits little of its energy as it traverses the material, as discussed in Section~\ref{sec:characteristics}. 
Even when the particle does decay before the calorimeter, the majority of its energy is carried away by the \ac{LSP} and not deposited in the calorimeter.
In both cases the energy is expected to be distributed across the layers of the calorimeters and not peaked in just one layer. 
This can be quantified in terms of \ep, the ratio of calorimeter energy of a nearby jet to the track momentum, and \emfrac, the fraction of energy in that jet within the electromagnetic calorimeter.
When no jets fall within a cone of 0.05 of the particle, \ep and \emfrac are both defined as zero.
\ep is expected to be above 1.0 for typical \ac{SM} particles because of calibration and the contributions from other nearby particles.
At these momenta there is no significant zero fraction due to interactions with the detector or insufficent energy deposits (see Section~\ref{sec:zero_fraction}). 
\emfrac is peaked close to 1.0 for electrons, and distributed between 10\% and 90\% for hadrons.

These trends can be seen in the two dimensional distribution for signal in Figure~\ref{fig:eoverp_emfrac} for stable and metastable (10 ns) events.
The majority of \rhadrons in both samples fall into the bin for $\ep = 0$ and $\emfrac = 0$ because the majority of the time there is no associated jet. 
When there is an associated jet \ep is typically still below 0.1, and the \emfrac is predominantly under 0.8.
Figure~\ref{fig:eoverp_emfrac} also includes simulated Z decays to electrons or tau leptons.
From the decays to electrons it is clear that the majority of electrons have \emfrac above 0.9.
The tau decays include a variety of products.
Muons can be seen in the bin where $\ep = 0$ and $\emfrac = 0$ because they do not have an associated jet.
Electrons fall into the range where $\ep > 1$ and $\emfrac > 0.9$.
Hadronic tau decays are the most common, and fall in the range of $0.1 < \emfrac < 0.9$ and $\ep > 1.0$. 

\begin{figure}[htb]
\centering
\subfloat[]{
  \includegraphics[width=\halffig]{figures/zee_eoverp_emfrac.pdf}
}
\subfloat[]{
  \includegraphics[width=\halffig]{figures/ztautau_eoverp_emfrac.pdf}
}\\
\subfloat[]{
  \includegraphics[width=\halffig]{figures/stable_eoverp_emfrac.pdf}
}
\subfloat[]{
  \includegraphics[draft, width=\halffig]{figures/metastable_eoverp_emfrac.pdf}
}
\caption{The normalized, two-dimensional distribution of $E/p$ and \emfrac for simulated (a) $Z\rightarrow ee$, (b) $Z\rightarrow \tau\tau$, (c) 1200 GeV Stable R-Hadron events, and (d) 1200 GeV, 10 ns R-Hadron events.}
\label{fig:eoverp_emfrac}
\end{figure}

These differences motivate an electron rejection by requiring an \emfrac below 0.9.
Similarly, isolated hadrons are rejected by requiring $\ep < 1.0$.
These requirements combine to remove the majority of isolated electrons and hadrons but retain over 95\% of the simulated signal across a range of masses and lifetimes.

% ----------------------------------------

\section{Ionization}

\subsection{dE/dx Calibration}

\subsection{Mass Estimation}
\label{sec:mass_requirement}
% ----------------------------------------
